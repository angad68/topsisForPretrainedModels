{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZZP3B1jE85zpNzSp6O+T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angad68/topsisForPretrainedModels/blob/main/topsisForPretrainedModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Dataset**"
      ],
      "metadata": {
        "id": "jL8BJ7UjQyCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Example data for Text Summarization models\n",
        "# Criteria: ROUGE, Inference Time, Model Size, F1 Score\n",
        "data = {\n",
        "    \"Model\": [\"BART\", \"T5\", \"Pegasus\", \"DistilBART\"],\n",
        "    \"ROUGE\": [0.85, 0.88, 0.86, 0.83],\n",
        "    \"Inference Time (ms)\": [120, 150, 110, 100],\n",
        "    \"Model Size (MB)\": [500, 400, 600, 350],\n",
        "    \"F1 Score\": [0.87, 0.89, 0.88, 0.84]\n",
        "}\n",
        "\n",
        "# Convert data to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Initial Data:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BkRuqrnQ59d",
        "outputId": "19f038be-d9f2-4a6b-ffb8-dcb11b594365"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data:\n",
            "        Model  ROUGE  Inference Time (ms)  Model Size (MB)  F1 Score\n",
            "0        BART   0.85                  120              500      0.87\n",
            "1          T5   0.88                  150              400      0.89\n",
            "2     Pegasus   0.86                  110              600      0.88\n",
            "3  DistilBART   0.83                  100              350      0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization**"
      ],
      "metadata": {
        "id": "gBen_LWIQ9Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(df, benefit_criteria):\n",
        "    norm_df = df.copy()\n",
        "    for col in df.columns[1:]:  # Exclude model names\n",
        "        if col in benefit_criteria:\n",
        "            norm_df[col] = df[col] / np.sqrt(np.sum(df[col] ** 2))  # Beneficial criteria\n",
        "        else:\n",
        "            norm_df[col] = np.sqrt(np.sum(df[col] ** 2)) / df[col]  # Non-beneficial criteria\n",
        "    return norm_df"
      ],
      "metadata": {
        "id": "sqSJDN7RRCPQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weight definition**"
      ],
      "metadata": {
        "id": "1FcN8U_GRFrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define weights for the criteria\n",
        "# ROUGE: 0.4, Inference Time: 0.2, Model Size: 0.2, F1 Score: 0.2\n",
        "weights = np.array([0.4, 0.2, 0.2, 0.2])\n",
        "benefit_criteria = [\"ROUGE\", \"F1 Score\"]  # Criteria where higher is better"
      ],
      "metadata": {
        "id": "DSIjfvPfRIrZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nromalization"
      ],
      "metadata": {
        "id": "-u8EhSK1RReo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df = normalize(df.drop(columns=[\"Model\"]), benefit_criteria)\n",
        "print(\"\\nNormalized Data:\")\n",
        "print(normalized_df)\n",
        "weighted_df = normalized_df * weights\n",
        "print(\"\\nWeighted Normalized Data:\")\n",
        "print(weighted_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzDI4fjoRPqo",
        "outputId": "88916c46-e4a4-42ed-c96e-0a7bdcc0c15d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Normalized Data:\n",
            "   ROUGE  Inference Time (ms)  Model Size (MB)  F1 Score\n",
            "0   0.85             2.024160         1.889444  0.499884\n",
            "1   0.88             1.619328         2.361805  0.511376\n",
            "2   0.86             2.208174         1.574537  0.505630\n",
            "3   0.83             2.428992         2.699206  0.482647\n",
            "\n",
            "Weighted Normalized Data:\n",
            "   ROUGE  Inference Time (ms)  Model Size (MB)  F1 Score\n",
            "0  0.340             0.404832         0.377889  0.099977\n",
            "1  0.352             0.323866         0.472361  0.102275\n",
            "2  0.344             0.441635         0.314907  0.101126\n",
            "3  0.332             0.485798         0.539841  0.096529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ideal Best/Worst -- Column Creation**"
      ],
      "metadata": {
        "id": "La8q2imqRlhd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoXC-KKbEJCC",
        "outputId": "65b220c2-b62e-46c3-e401-917f88a2037e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Ranking:\n",
            "        Model  ROUGE  Inference Time (ms)  Model Size (MB)  F1 Score  \\\n",
            "3  DistilBART   0.83                  100              350      0.84   \n",
            "1          T5   0.88                  150              400      0.89   \n",
            "0        BART   0.85                  120              500      0.87   \n",
            "2     Pegasus   0.86                  110              600      0.88   \n",
            "\n",
            "   TOPSIS Score  Rank  \n",
            "3      0.930164   1.0  \n",
            "1      0.475157   2.0  \n",
            "0      0.361951   3.0  \n",
            "2      0.340584   4.0  \n"
          ]
        }
      ],
      "source": [
        "ideal_best = weighted_df.max()\n",
        "ideal_worst = weighted_df.min()\n",
        "\n",
        "distance_to_best = np.sqrt(((weighted_df - ideal_best) ** 2).sum(axis=1))\n",
        "distance_to_worst = np.sqrt(((weighted_df - ideal_worst) ** 2).sum(axis=1))\n",
        "\n",
        "closeness = distance_to_worst / (distance_to_best + distance_to_worst)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cpEwUGDEQwEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[\"TOPSIS Score\"] = closeness\n",
        "df[\"Rank\"] = df[\"TOPSIS Score\"].rank(ascending=False)\n",
        "\n",
        "print(\"\\nFinal Ranking:\")\n",
        "print(df.sort_values(\"Rank\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iqy-trjGne8",
        "outputId": "e7708dbe-87a5-40d0-994e-05b973c9c21f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Ranking:\n",
            "        Model  ROUGE  Inference Time (ms)  Model Size (MB)  F1 Score  \\\n",
            "3  DistilBART   0.83                  100              350      0.84   \n",
            "1          T5   0.88                  150              400      0.89   \n",
            "0        BART   0.85                  120              500      0.87   \n",
            "2     Pegasus   0.86                  110              600      0.88   \n",
            "\n",
            "   TOPSIS Score  Rank  \n",
            "3      0.930164   1.0  \n",
            "1      0.475157   2.0  \n",
            "0      0.361951   3.0  \n",
            "2      0.340584   4.0  \n"
          ]
        }
      ]
    }
  ]
}